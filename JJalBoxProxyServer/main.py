# main.py
# ì‹¤í–‰: uvicorn main:app --host 0.0.0.0 --port 8000

# ==========================================
# 1. Enum / Import / í™˜ê²½ ë³€ìˆ˜ ë¡œë”©
# ==========================================
from enum import Enum
from typing import Optional, List, Any

import os, base64, io
import requests
from openai import OpenAI
from google import genai
from google.genai import types
from fastapi import FastAPI, UploadFile, File, Form, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from dotenv import load_dotenv
from PIL import Image, ImageDraw, ImageFont
import json

# Provider ì„ íƒ (í”„ë¡ íŠ¸ enumê³¼ ë™ì¼)
class Provider(str, Enum):
    GPT = "gpt"
    GEMINI = "gemini"
    MEME_GALTEYA = "meme_galteya"
    SNOW_NIGHT = "snow_night"
    PIXEL_ART = "pixel_art"
    AC_STYLE = "ac_style"

# í™˜ê²½ ë³€ìˆ˜ ë¡œë”©
load_dotenv(os.getenv("ENV_PATH"))
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "")
OPENAI_BASE = os.getenv("OPENAI_BASE_URL", "")
GEMINI_BASE = os.getenv("GEMINI_BASE_URL", "")
OPENAI_IMAGE_MODEL = os.getenv("OPENAI_IMAGE_MODEL", "")
GEMINI_IMAGE_MODEL = os.getenv("GEMINI_IMAGE_MODEL", "")


# FastAPI ì•± ë° CORS ì„¤ì •
app = FastAPI(title="Image Proxy")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],          # TODO: ë°°í¬ ì‹œ ë„ë©”ì¸ ì œí•œ
    allow_methods=["*"],
    allow_headers=["*"],
)


# ==========================================
# 2. ê³µí†µ ìœ í‹¸ í•¨ìˆ˜
# ==========================================

def _png_bytes(img_bytes: bytes) -> bytes:
    """ì„ì˜ í¬ë§· ë°”ì´íŠ¸ë¥¼ PNGë¡œ ë³€í™˜(ì¼ê´€ì„± ë³´ì¥). ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜."""
    ...

def _normalize_upload_image(upload: UploadFile):
    """
    ì—…ë¡œë“œëœ ì´ë¯¸ì§€ë¥¼ ì½ì–´ì„œ:
      - ì§€ì›í•˜ì§€ ì•ŠëŠ” í¬ë§·ì´ë©´ PNGë¡œ ë³€í™˜
      - (ë°”ì´íŠ¸, mime, filename) íŠœí”Œë¡œ ë°˜í™˜
    """
    ...

def _http_err_from_requests(resp: requests.Response):
    """requests.Responseë¥¼ HTTPExceptionìœ¼ë¡œ ë³€í™˜ (ë””ë²„ê·¸ìš© ì—ëŸ¬ ë©”ì‹œì§€ í¬í•¨)."""
    ...


# ==========================================
# 3. ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸ í—¬í¼
#    (Providerë³„ ìŠ¤íƒ€ì¼ ì„¤ëª…ì„ í”„ë¡¬í”„íŠ¸ì— ì–¹ëŠ” ì—­í• )
# ==========================================

def _style_prompt_meme_galteya(prompt: str) -> str:
    """ê°ˆí…Œì•¼í…Œì•¼ ë°ˆ ìŠ¤íƒ€ì¼ìš© í”„ë¡¬í”„íŠ¸ ë˜í•‘."""
    ...

def _style_prompt_snow_night(prompt: str) -> str:
    """ëˆˆ ë‚´ë¦¬ëŠ” ë°¤ ì¼ëŸ¬ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ìš© í”„ë¡¬í”„íŠ¸ ë˜í•‘."""
    ...

def _style_prompt_pixel_art(prompt: str) -> str:
    """í”½ì…€ ì•„íŠ¸(16ë¹„íŠ¸ ê²Œì„) ìŠ¤íƒ€ì¼ìš© í”„ë¡¬í”„íŠ¸ ë˜í•‘."""
    ...

def _style_prompt_ac_style(prompt: str) -> str:
    """ë™ë¬¼ì˜ ìˆ²í’ ì¹´íˆ° ìŠ¤íƒ€ì¼ìš© í”„ë¡¬í”„íŠ¸ ë˜í•‘."""
    ...


# ==========================================
# 4. ë²¤ë” í˜¸ì¶œ í•¨ìˆ˜ (ì‹¤ì œ OpenAI/Gemini API í˜¸ì¶œ)
#    ì—¬ê¸°ì„œëŠ” "bytes"ë§Œ ë°˜í™˜í•˜ê³ , ResponseëŠ” ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ë§Œë“ ë‹¤.
# ==========================================

# ---------- 4-1. OpenAI / GPT-Image-1 ê³„ì—´ ----------

def _openai_text2image(prompt: str) -> bytes:
    """
    GPT-Image-1 text -> image
    - promptë¥¼ ë°›ì•„ ì§ì ‘ API í˜¸ì¶œ
    - ë°˜í™˜: raw jpeg ì´ë¯¸ì§€ ë°”ì´íŠ¸
    """

    # ì‚¬ì „ ê²€ì¦
    if not OPENAI_API_KEY:
        raise HTTPException(500, "OpenAI API key missing")
    if not OPENAI_IMAGE_MODEL:
        raise HTTPException(500, "OPENAI_IMAGE_MODEL is not set")
    
    client = OpenAI(api_key=OPENAI_API_KEY)

    resp = client.images.generate( prompt=prompt, model=OPENAI_IMAGE_MODEL, n=1, output_format="jpeg" )
    raw_bytes = base64.b64decode(resp.data[0].b64_json)
    return raw_bytes

def _openai_text_with_refs(
    prompt: str,
    images: List[UploadFile],
) -> bytes:
    """
    GPT-Image-1 text + reference images -> image
    - ì—…ë¡œë“œëœ ì´ë¯¸ì§€ë¥¼ ì°¸ì¡°ë¡œ ì“°ëŠ” text2image
    """
    ...

def _openai_img_edit(
    prompt: str,
    base_image: UploadFile,
    mask_image: Optional[UploadFile] = None,
) -> bytes:
    """
    GPT-Image-1 ì´ë¯¸ì§€ í¸ì§‘ (image -> image / ì¸í˜ì¸íŒ…)
    - /images/edits ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©
    """
    ...


# ---------- 4-2. Gemini ê³„ì—´ (ë‚˜ì¤‘ì— êµ¬í˜„) ----------

def _gemini_text2image(prompt: str, images: Optional[List[UploadFile]]) -> bytes:
    """
    Gemini text -> image
    """

    # ì‚¬ì „ ê²€ì¦
    if not GEMINI_API_KEY:
        raise HTTPException(500, "Gemini API key missing")
    if not GEMINI_IMAGE_MODEL:
        raise HTTPException(500, "GEMINI_IMAGE_MODEL is not set")

    client = genai.Client(api_key=GEMINI_API_KEY)

    contents = [prompt]
    if images:
        for image in images:
            img_b = image.file.read()
            b64 = base64.b64encode(img_b).decode("utf-8")
            contents.append({
                "inlineData": {
                    "mimeType": "image/png",
                    "data": b64
                }
            })

    resp = client.models.generate_content(
        model=GEMINI_IMAGE_MODEL,
        contents=contents
    )

    for part in resp.parts:
        if part.text is not None:
            print(part.text)
        elif part.inline_data is not None:
            raw_bytes = part.inline_data.data
            return raw_bytes


def _gemini_img2img(
    prompt: str,
    images: List[UploadFile],
) -> bytes:
    """
    Gemini image -> image
    """
    ...


# ==========================================
# 5. ì´ë¯¸ì§€ ìƒì„± ì—”ë“œí¬ì¸íŠ¸ (+ providerë³„ ë¶„ê¸°ê¹Œì§€ í•œ ê³³ì—ì„œ ì²˜ë¦¬)
# ==========================================

@app.post("/v1/images/generate")
async def generate_image(
    provider: Provider = Form(...),
    prompt: str = Form(...),
    images: Optional[List[UploadFile]] = File(None),
):
    """
    ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸:
      1) providerë³„ ë™ì‘ ì •ì˜
      2) ë²¤ë” í—¬í¼ í˜¸ì¶œ
      3) bytes -> PNGë¡œ ë³€í™˜ í›„ StreamingResponse ë°˜í™˜
    """
    try:
        # 1. providerë³„ ë™ì‘ ì •ì˜
        #    ğŸ‘‰ ì§€ê¸ˆì€ GPT-Image-1ë§Œ ë¨¼ì € ì œëŒ€ë¡œ ë¶™ì´ê³ ,
        #       ë‚˜ì¤‘ì— Gemini / ìŠ¤íƒ€ì¼ í”„ë¦¬ì…‹ì„ ì±„ì›Œ ë„£ëŠ” ë°©í–¥ìœ¼ë¡œ.

        # ----- ê¸°ë³¸ GPT provider -----
        if provider == Provider.GPT:
            img_bytes = _openai_text2image(prompt)
            return StreamingResponse(io.BytesIO(img_bytes), media_type="image/jpeg")

    

        # ----- ê¸°ë³¸ Gemini provider -----
        elif provider == Provider.GEMINI:
            img_bytes = _gemini_text2image(prompt, images)
            return StreamingResponse(io.BytesIO(img_bytes), media_type="image/png")

        """
        # ----- ë°ˆ/ìŠ¤íƒ€ì¼ providerë“¤ (ë‚˜ì¤‘ì— êµ¬í˜„) -----
        elif provider == Provider.MEME_GALTEYA:
            # 1) ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸ ì ìš©
            # 2) GPT provider í”Œë¡œìš°ë¥¼ ì¬ì‚¬ìš©
            styled = _style_prompt_meme_galteya(prompt)
            # ì—¬ê¸°ì„œëŠ” GPT text2imageì™€ ë™ì¼í•˜ê²Œ ë™ì‘ì‹œí‚¤ê±°ë‚˜,
            # ë‚˜ì¤‘ì— í…œí”Œë¦¿/ì¸í˜ì¸íŒ…ìœ¼ë¡œ ë³€ê²½ ê°€ëŠ¥
            if mode == "text2image":
                if not images:
                    img_bytes = _openai_text2image(styled)
                else:
                    img_bytes = _openai_text_with_refs(styled, images)
            else:
                if not images:
                    raise HTTPException(400, "edit mode requires at least one image")
                base_image = images[0]
                img_bytes = _openai_img_edit(styled, base_image)

        elif provider == Provider.SNOW_NIGHT:
            # Gemini image -> image ì „ìš©ìœ¼ë¡œ ì„¤ê³„
            if not images:
                raise HTTPException(400, "snow_night requires at least one image")
            styled = _style_prompt_snow_night(prompt)
            img_bytes = _gemini_img2img(styled, images)

        elif provider == Provider.PIXEL_ART:
            # GPT image -> image (ì°¸ì¡° ì´ë¯¸ì§€ í•„ìˆ˜)
            if not images:
                raise HTTPException(400, "pixel_art requires at least one image")
            styled = _style_prompt_pixel_art(prompt)
            img_bytes = _openai_text_with_refs(styled, images)

        elif provider == Provider.AC_STYLE:
            # GPT image -> image (ì°¸ì¡° ì´ë¯¸ì§€ í•„ìˆ˜)
            if not images:
                raise HTTPException(400, "ac_style requires at least one image")
            styled = _style_prompt_ac_style(prompt)
            img_bytes = _openai_text_with_refs(styled, images)

        else:
            raise HTTPException(400, "unsupported provider")
        """
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ==========================================
# 7. Meme Template Based Feature (ê¸°ì¡´ ê¸°ëŠ¥)
# ==========================================

# í…œí”Œë¦¿ ë¡œë“œ
# with open("templates/galteya.json", "r", encoding="utf-8") as f:
#     TEMPLATE_GALTEYA = json.load(f)

@app.get("/v1/templates")
def list_templates():
    """í…œí”Œë¦¿ ëª©ë¡ ì¡°íšŒ."""
    ...

@app.get("/v1/templates/{tid}")
def get_template(tid: str):
    """íŠ¹ì • í…œí”Œë¦¿ ìƒì„¸ ì¡°íšŒ."""
    ...

@app.post("/v1/memes/{tid}/generate")
async def generate_meme(
    tid: str,
    inputs: str = Form(...),
    files: List[UploadFile] = File(None),
):
    """
    í…œí”Œë¦¿ ê¸°ë°˜ ë°ˆ ì´ë¯¸ì§€ ìƒì„±:
      - base_url ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì™€,
      - slots ì •ë³´ì— ë”°ë¼ í…ìŠ¤íŠ¸ í•©ì„±,
      - inpaint ì˜ì—­(mask) ëª¨ì•„ì„œ _call_inpaintë¡œ OpenAI ì´ë¯¸ì§€ í¸ì§‘ ìš”ì²­.
    """
    ...


# ==========================================
# 8. í…œí”Œë¦¿/ì¸í˜ì¸íŒ… ë‚´ë¶€ ìœ í‹¸
# ==========================================

def _draw_text(img, text, bbox, font_spec):
    """ì§€ì •ëœ bbox ì˜ì—­ì— í…ìŠ¤íŠ¸ë¥¼ ë Œë”ë§."""
    ...

def _merge_masks(mask_images):
    """ì—¬ëŸ¬ ê°œì˜ ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ë¥¼ í•˜ë‚˜ë¡œ í•©ì„±."""
    ...

def _call_inpaint(base_bytes, mask_bytes, prompt):
    """OpenAI /images/editsë¡œ ì¸í˜ì¸íŒ… í˜¸ì¶œ."""
    ...


@app.post("/api/meme_edit")
async def edit_meme_image(
    prompt: str = Form(...),
    base_image: UploadFile = File(...),
    mask_image: UploadFile = File(...)
):
    """í…ŒìŠ¤íŠ¸ìš© ì¸í˜ì¸íŒ… ì—”ë“œí¬ì¸íŠ¸."""
    ...
